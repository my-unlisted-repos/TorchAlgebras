{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2de19b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MetadataTensor(object):\n",
    "    def __init__(self, data, metadata=None, **kwargs):\n",
    "        self._t = torch.as_tensor(data, **kwargs)\n",
    "        self._sussy_metadata = metadata\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self._t.shape} metadata {self._sussy_metadata}\"\n",
    "\n",
    "    @classmethod\n",
    "    def __torch_function__(cls, func, types, args=(), kwargs=None):\n",
    "        print()\n",
    "        print(f'{cls = }')\n",
    "        print(f'{func = }')\n",
    "        print(f'{func.__name__ = }')\n",
    "        if kwargs is None:\n",
    "            kwargs = {}\n",
    "        metadata = None\n",
    "        all_args = list(args) + list(kwargs.values())\n",
    "        for i, arg in enumerate(all_args):\n",
    "            print(f'{i = }, {arg = }, {arg.__class__.__name__ = }')\n",
    "            if hasattr(arg, '_sussy_metadata'):\n",
    "                metadata = arg._sussy_metadata\n",
    "                break\n",
    "        args = [a._t if hasattr(a, '_t') else a for a in args]\n",
    "        kwargs = {k: v._t if isinstance(v, MetadataTensor) else v for k, v in kwargs.items()}\n",
    "        ret = func(*args, **kwargs)\n",
    "        return cls(ret, metadata=metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f55947ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cls = <class '__main__.MetadataTensor'>\n",
      "func = <method 'clamp' of 'torch._C.TensorBase' objects>\n",
      "func.__name__ = 'clamp'\n",
      "i = 0, arg = tensor([[ 1.2620, -0.0875, -0.9023, -1.1289]]), arg.__class__.__name__ = 'Tensor'\n",
      "i = 1, arg = torch.Size([1, 4]) metadata big chungus, arg.__class__.__name__ = 'MetadataTensor'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4]) metadata big chungus"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sus = MetadataTensor(torch.randn(1,4), 'big chungus')\n",
    "torch.randn(1,4).clamp(min=sus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "468aeaf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['add',\n",
       " 'div',\n",
       " 'matmul',\n",
       " 'max',\n",
       " 'min',\n",
       " 'mm',\n",
       " 'mul',\n",
       " 'neg',\n",
       " 'pow',\n",
       " 'reciprocal',\n",
       " 'sub',\n",
       " 'sum']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pyright: reportIncompatibleMethodOverride=false\n",
    "# pylint: disable=abstract-method\n",
    "import math\n",
    "\n",
    "from typing import Any, Literal\n",
    "import torch\n",
    "\n",
    "NumberOrTensor = torch.Tensor\n",
    "class Algebra:\n",
    "    def add(self, x: torch.Tensor, y: \"NumberOrTensor\") -> torch.Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def neg(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def sub(self, x: torch.Tensor, y: \"NumberOrTensor\") -> torch.Tensor:\n",
    "        return self.neg(self.add(self.neg(x), y)) # can be overridden\n",
    "\n",
    "    def mul(self, x: torch.Tensor, y: \"NumberOrTensor\") -> torch.Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def div(self, x: torch.Tensor, y: \"NumberOrTensor\") -> torch.Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def reciprocal(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def pow(self, base: torch.Tensor, exponent: \"NumberOrTensor\") -> torch.Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def sum(self, x: torch.Tensor, dim: int | None = None, keepdim=False) -> torch.Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def min(self, x: torch.Tensor, dim: int | None = None, keepdim=False) -> torch.Tensor:\n",
    "        if dim is None: return torch.min(x)\n",
    "        return x.amin(dim, keepdim)\n",
    "\n",
    "    def max(self, x: torch.Tensor, dim: int | None = None, keepdim=False) -> torch.Tensor:\n",
    "        if dim is None: return torch.max(x)\n",
    "        return x.amax(dim, keepdim)\n",
    "\n",
    "    def matmul(self, x: torch.Tensor, y: torch.Tensor):\n",
    "        # this imlements matmul by calling add and mul\n",
    "\n",
    "        x_squeeze = False\n",
    "        y_squeeze = False\n",
    "\n",
    "        if x.ndim == 1:\n",
    "            x_squeeze = True\n",
    "            x = x.unsqueeze(0)\n",
    "\n",
    "        if y.ndim == 1:\n",
    "            y_squeeze = True\n",
    "            y = y.unsqueeze(1)\n",
    "\n",
    "        res = self.sum(self.mul(x.unsqueeze(-1), y.unsqueeze(-3)), dim = -2)\n",
    "\n",
    "        if x_squeeze: res = res.squeeze(-2)\n",
    "        if y_squeeze: res = res.squeeze(-1)\n",
    "\n",
    "        return res\n",
    "\n",
    "    def mm(self, x:torch.Tensor, y:torch.Tensor):\n",
    "        return self.matmul(x, y)\n",
    "    \n",
    "[v for v in dir(Algebra) if not v.startswith('_')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
